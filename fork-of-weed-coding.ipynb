{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8763581,"sourceType":"datasetVersion","datasetId":5265556},{"sourceId":69167,"sourceType":"modelInstanceVersion","modelInstanceId":57697,"modelId":79670},{"sourceId":69613,"sourceType":"modelInstanceVersion","modelInstanceId":58088,"modelId":80232},{"sourceId":69617,"sourceType":"modelInstanceVersion","modelInstanceId":58091,"modelId":80235},{"sourceId":70085,"sourceType":"modelInstanceVersion","modelInstanceId":58496,"modelId":80803}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-09-03T15:02:22.244196Z","iopub.execute_input":"2024-09-03T15:02:22.245198Z","iopub.status.idle":"2024-09-03T15:02:22.250575Z","shell.execute_reply.started":"2024-09-03T15:02:22.245158Z","shell.execute_reply":"2024-09-03T15:02:22.249474Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import resnet50\nimport pytorch_lightning as pl\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch.cuda\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\nimport torchvision.models as models\nfrom pytorch_lightning.callbacks import EarlyStopping\nfrom pytorch_lightning.callbacks import ProgressBar","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/weed-dataset/weeds/weeds_dataset/\"\n\ndef add_path(image_name):\n    return path + image_name\n\ndef remove_missing_images(dataframe, root_dir, image_filename_column='path'):\n    missing_indices = []\n    for index, row in dataframe.iterrows():\n        image_path = os.path.join(root_dir, row[image_filename_column])\n        if not os.path.exists(image_path):\n            missing_indices.append(index)\n    cdf = dataframe.drop(index=missing_indices).reset_index(drop=True)\n    return cdf\n\ntrain0 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/train_subset0.csv')\ntrain1 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/train_subset1.csv')\ntrain2 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/train_subset2.csv')\ntrain3 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/train_subset3.csv')\ntrain4 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/train_subset4.csv')\ntraining_data = pd.concat([train0, train1, train2, train3, train4], ignore_index=True)\n\ntest0 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/test_subset0.csv')\ntest1 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/test_subset1.csv')\ntest2 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/test_subset2.csv')\ntest3 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/test_subset3.csv')\ntest4 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/test_subset4.csv')\ntesting_data = pd.concat([test0, test1, test2, test3, test4], ignore_index=True)\n\nval0 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/val_subset0.csv')\nval1 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/val_subset1.csv')\nval2 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/val_subset2.csv')\nval3 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/val_subset3.csv')\nval4 = pd.read_csv('/kaggle/input/weed-dataset/weeds/labels/val_subset4.csv')\nvalidation_data = pd.concat([val0, val1, val2, val3, val4], ignore_index=True)\n\nnum_of_classes=max(train0[\"Label\"].unique().size, testing_data[\"Label\"].unique().size, val0[\"Label\"].unique().size)\n\ntraining_data = training_data.rename(columns={\"Filename\": \"path\"})\ntesting_data = testing_data.rename(columns={\"Filename\": \"path\"})\nvalidation_data = validation_data.rename(columns={\"Filename\": \"path\"})\n\ntraining_data[\"path\"] = training_data[\"path\"].apply(add_path)\ntesting_data[\"path\"] = testing_data[\"path\"].apply(add_path)\nvalidation_data[\"path\"] = validation_data[\"path\"].apply(add_path)\n\ntraining_data = remove_missing_images(training_data, path)\ntesting_data = remove_missing_images(testing_data, path)\nvalidation_data = remove_missing_images(validation_data, path)\n\nx_train = training_data[\"path\"].tolist()\ny_train = training_data[\"Label\"].tolist()\nx_val = validation_data[\"path\"].tolist()\ny_val = validation_data[\"Label\"].tolist()\nx_test = testing_data[\"path\"].tolist()\ny_test = testing_data[\"Label\"].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:02:27.322663Z","iopub.execute_input":"2024-09-03T15:02:27.323442Z","iopub.status.idle":"2024-09-03T15:03:05.220341Z","shell.execute_reply.started":"2024-09-03T15:02:27.323400Z","shell.execute_reply":"2024-09-03T15:03:05.219348Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"training_data","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.222152Z","iopub.execute_input":"2024-09-03T15:03:05.222481Z","iopub.status.idle":"2024-09-03T15:03:05.234539Z","shell.execute_reply.started":"2024-09-03T15:03:05.222454Z","shell.execute_reply":"2024-09-03T15:03:05.233500Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"                                                    path  Label\n0      /kaggle/input/weed-dataset/weeds/weeds_dataset...      5\n1      /kaggle/input/weed-dataset/weeds/weeds_dataset...      1\n2      /kaggle/input/weed-dataset/weeds/weeds_dataset...      0\n3      /kaggle/input/weed-dataset/weeds/weeds_dataset...      1\n4      /kaggle/input/weed-dataset/weeds/weeds_dataset...      3\n...                                                  ...    ...\n52512  /kaggle/input/weed-dataset/weeds/weeds_dataset...      3\n52513  /kaggle/input/weed-dataset/weeds/weeds_dataset...      7\n52514  /kaggle/input/weed-dataset/weeds/weeds_dataset...      8\n52515  /kaggle/input/weed-dataset/weeds/weeds_dataset...      8\n52516  /kaggle/input/weed-dataset/weeds/weeds_dataset...      8\n\n[52517 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>52512</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>52513</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>52514</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>52515</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>52516</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>52517 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"training_data[training_data['Label'] == 3].count()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.236033Z","iopub.execute_input":"2024-09-03T15:03:05.236427Z","iopub.status.idle":"2024-09-03T15:03:05.250819Z","shell.execute_reply.started":"2024-09-03T15:03:05.236391Z","shell.execute_reply":"2024-09-03T15:03:05.249813Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"path     3066\nLabel    3066\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"testing_data.Label.unique()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.254044Z","iopub.execute_input":"2024-09-03T15:03:05.254801Z","iopub.status.idle":"2024-09-03T15:03:05.261906Z","shell.execute_reply.started":"2024-09-03T15:03:05.254769Z","shell.execute_reply":"2024-09-03T15:03:05.260902Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"array([0, 8, 7, 1, 4, 3, 5, 2, 6])"},"metadata":{}}]},{"cell_type":"code","source":"testing_data","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.263189Z","iopub.execute_input":"2024-09-03T15:03:05.263545Z","iopub.status.idle":"2024-09-03T15:03:05.278892Z","shell.execute_reply.started":"2024-09-03T15:03:05.263517Z","shell.execute_reply":"2024-09-03T15:03:05.277441Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"                                                    path  Label\n0      /kaggle/input/weed-dataset/weeds/weeds_dataset...      0\n1      /kaggle/input/weed-dataset/weeds/weeds_dataset...      0\n2      /kaggle/input/weed-dataset/weeds/weeds_dataset...      0\n3      /kaggle/input/weed-dataset/weeds/weeds_dataset...      0\n4      /kaggle/input/weed-dataset/weeds/weeds_dataset...      0\n...                                                  ...    ...\n17502  /kaggle/input/weed-dataset/weeds/weeds_dataset...      8\n17503  /kaggle/input/weed-dataset/weeds/weeds_dataset...      8\n17504  /kaggle/input/weed-dataset/weeds/weeds_dataset...      8\n17505  /kaggle/input/weed-dataset/weeds/weeds_dataset...      8\n17506  /kaggle/input/weed-dataset/weeds/weeds_dataset...      8\n\n[17507 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17502</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>17503</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>17504</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>17505</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>17506</th>\n      <td>/kaggle/input/weed-dataset/weeds/weeds_dataset...</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>17507 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, image_paths, targets, transform=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert('RGB')\n        target = self.targets[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, target","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.280219Z","iopub.execute_input":"2024-09-03T15:03:05.280661Z","iopub.status.idle":"2024-09-03T15:03:05.288969Z","shell.execute_reply.started":"2024-09-03T15:03:05.280631Z","shell.execute_reply":"2024-09-03T15:03:05.287643Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class ImageClassifier:\n    def __init__(self, model, train_loader, test_loader, val_loader=None):\n        self.model = model\n        self.train_loader = train_loader\n        self.test_loader = test_loader\n        if val_loader is not None:\n            self.val_loader = val_loader\n\n    def fitt(self, epochs=1):\n        callbacks = self.model.configure_callbacks()\n        trainer = pl.Trainer(callbacks = callbacks, max_epochs=epochs)\n        trainer.gpus=2\n        if self.val_loader is not None:\n            trainer.fit(self.model, self.train_loader, self.val_loader)\n        trainer.fit(self.model, self.train_loader)\n\n    def predict(self):\n        self.model.eval()\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(device)\n        predictions = []\n        with torch.no_grad():\n            for inputs, _ in self.test_loader:\n                inputs = inputs.to(device)\n                outputs = self.model(inputs)\n                predictions.append(outputs)\n        return predictions\n\n    def predict_proba(self):\n        self.model.eval()\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(device)\n        prediction_proba = []\n        softmax = nn.Softmax(dim=1)\n        with torch.no_grad():\n            for inputs, _ in self.test_loader:\n                inputs = inputs.to(device)\n                outputs = self.model(inputs)\n                prediction_proba.append(softmax(outputs))\n        return prediction_proba\n\n    def predict_single(self, image_path, transform):\n        self.model.eval()\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(device)\n        \n        image = Image.open(image_path).convert('RGB')\n\n        if transform:\n            image = transform(image).unsqueeze(0).to(device)\n        \n        with torch.no_grad():\n            output = self.model(image)\n        \n        return output\n\n    def predict_single_proba(self, image_path, transform):\n        self.model.eval()\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(device)\n        \n        image = Image.open(image_path).convert('RGB')\n\n        if transform:\n            image = transform(image).unsqueeze(0).to(device)\n        \n        with torch.no_grad():\n            output = self.model(image)\n            proba = nn.Softmax(dim=1)(output)\n        \n        return proba\n    \n    def Confussion_matrix(self):\n        self.model.eval()\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(device)\n        correct = 0\n        total = 0\n        predicted_labels = []\n        true_labels = []\n\n        with torch.no_grad():\n            for inputs, targets in self.test_loader:\n                inputs = inputs.to(device)\n                targets = targets.to(device)\n                outputs = self.model(inputs)\n                _, predicted = torch.max(outputs, 1)\n                total += targets.size(0)\n                correct += (predicted == targets).sum().item()\n                predicted_labels.extend(predicted.cpu().numpy())\n                true_labels.extend(targets.cpu().numpy())\n\n        accuracy = 100 * correct / total\n        print(f'Accuracy on test data: {accuracy:.2f}%')\n\n        precision = precision_score(true_labels, predicted_labels, average='macro')\n        recall = recall_score(true_labels, predicted_labels, average='macro')\n        f1 = f1_score(true_labels, predicted_labels, average='macro')\n\n        print('Precision: {:.4f}'.format(precision))\n        print('Recall: {:.4f}'.format(recall))\n        print('F1 Score: {:.4f}'.format(f1))\n\n        conf_matrix = confusion_matrix(true_labels, predicted_labels)\n        print('Confusion Matrix:')\n        print(conf_matrix)\n        \n    def save_model(self, save_path):\n        torch.save(RestNet_50_model.state_dict(), save_path)\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNetClassifier(pl.LightningModule):\n    def __init__(self, learning_rate=0.01, num_of_classes=9, y_train=y_train):\n        super(ResNetClassifier, self).__init__()\n        self.model = resnet50(pretrained=False)\n        num_ftrs = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_ftrs, num_of_classes)\n        self.learning_rate = learning_rate\n\n        class_sample_count = np.array([sum(y_train == t) for t in np.unique(y_train)])\n        weight = 1. / class_sample_count\n        samples_weight = np.array([weight[t] for t in y_train])\n        self.class_weights = torch.FloatTensor(weight).to(self.device)\n\n        self.criterion = nn.CrossEntropyLoss(weight=self.class_weights)\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = self.criterion(outputs, labels)\n        self.log('train_loss', loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.9)\n        return optimizer\n\n    def on_train_epoch_end(self):\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.290273Z","iopub.execute_input":"2024-09-03T15:03:05.290585Z","iopub.status.idle":"2024-09-03T15:03:05.301591Z","shell.execute_reply.started":"2024-09-03T15:03:05.290558Z","shell.execute_reply":"2024-09-03T15:03:05.300597Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def image_transform(image):\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    return transform(image)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.302747Z","iopub.execute_input":"2024-09-03T15:03:05.303141Z","iopub.status.idle":"2024-09-03T15:03:05.317437Z","shell.execute_reply.started":"2024-09-03T15:03:05.303115Z","shell.execute_reply":"2024-09-03T15:03:05.316489Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train_dataset_Restnet_50 = CustomImageDataset(x_train, y_train, transform=image_transform)\ntest_dataset_Restnet_50 = CustomImageDataset(x_test, y_test, transform=image_transform)\n\ntrain_loader_Restnet_50 = DataLoader(train_dataset_Restnet_50, batch_size=32, shuffle=True)\ntest_loader_Restnet_50 = DataLoader(test_dataset_Restnet_50, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.318556Z","iopub.execute_input":"2024-09-03T15:03:05.318875Z","iopub.status.idle":"2024-09-03T15:03:05.327689Z","shell.execute_reply.started":"2024-09-03T15:03:05.318825Z","shell.execute_reply":"2024-09-03T15:03:05.326852Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"RestNet_50 = ResNetClassifier()\nprint(RestNet_50)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-03T15:03:05.331668Z","iopub.execute_input":"2024-09-03T15:03:05.332062Z","iopub.status.idle":"2024-09-03T15:03:05.990265Z","shell.execute_reply.started":"2024-09-03T15:03:05.332036Z","shell.execute_reply":"2024-09-03T15:03:05.989140Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"ResNetClassifier(\n  (model): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=9, bias=True)\n  )\n  (criterion): CrossEntropyLoss()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"RestNet_50_model = ImageClassifier(RestNet_50, train_loader_Restnet_50, test_dataset_Restnet_50)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RestNet_50_model.fitt(epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:05.991488Z","iopub.execute_input":"2024-09-03T15:03:05.991808Z","iopub.status.idle":"2024-09-03T15:03:06.050249Z","shell.execute_reply.started":"2024-09-03T15:03:05.991781Z","shell.execute_reply":"2024-09-03T15:03:06.049446Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"RestNet_50_model.Confussion_matrix()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:09:34.951557Z","iopub.execute_input":"2024-06-29T16:09:34.952298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = '/kaggle/working/my_model_Restnet_50.pth'\nRestNet_50_model.save_model(save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class InceptionV3Classifier(pl.LightningModule):\n    def __init__(self, learning_rate=0.01, num_of_classes=9, y_train=None):\n        super(InceptionV3Classifier, self).__init__()\n        self.model = models.inception_v3(pretrained=False)\n        \n        num_ftrs = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_ftrs, num_of_classes)\n        \n        num_aux_ftrs = self.model.AuxLogits.fc.in_features\n        self.model.AuxLogits.fc = nn.Linear(num_aux_ftrs, num_of_classes)\n        \n        self.learning_rate = learning_rate\n        \n        if y_train is not None:\n            class_sample_count = np.array([sum(y_train == t) for t in np.unique(y_train)])\n            weight = 1. / class_sample_count\n            self.class_weights = torch.FloatTensor(weight).to(self.device)\n        else:\n            self.class_weights = None\n\n        self.criterion = nn.CrossEntropyLoss(weight=self.class_weights)\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        inputs, labels = batch\n        inputs, labels = inputs.to(self.device), labels.to(self.device)\n        outputs = self(inputs)\n\n        # The InceptionV3 model returns a tuple of (main_output, aux_output)\n        main_output, aux_output = outputs.logits, outputs.aux_logits\n\n        loss1 = self.criterion(main_output, labels)\n        loss2 = self.criterion(aux_output, labels)\n        loss = loss1 + 0.4 * loss2\n\n        self.log('train_loss', loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.9)\n        return optimizer\n\n    def on_train_epoch_end(self):\n        torch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:06.051437Z","iopub.execute_input":"2024-09-03T15:03:06.051788Z","iopub.status.idle":"2024-09-03T15:03:06.064881Z","shell.execute_reply.started":"2024-09-03T15:03:06.051754Z","shell.execute_reply":"2024-09-03T15:03:06.063752Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def image_transform1(image):\n    transform = transforms.Compose([\n        transforms.Resize((299, 299)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    return transform(image)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:06.066216Z","iopub.execute_input":"2024-09-03T15:03:06.066522Z","iopub.status.idle":"2024-09-03T15:03:06.078049Z","shell.execute_reply.started":"2024-09-03T15:03:06.066496Z","shell.execute_reply":"2024-09-03T15:03:06.077049Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"train_dataset_InceptionV3 = CustomImageDataset(x_train, y_train, transform=image_transform1)\ntest_dataset_InceptionV3 = CustomImageDataset(x_test, y_test, transform=image_transform1)\n\ntrain_loader_InceptionV3 = DataLoader(train_dataset_InceptionV3, batch_size=16, shuffle=True)\ntest_loader_InceptionV3 = DataLoader(test_dataset_InceptionV3, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T13:46:17.205418Z","iopub.execute_input":"2024-09-03T13:46:17.206339Z","iopub.status.idle":"2024-09-03T13:46:17.211587Z","shell.execute_reply.started":"2024-09-03T13:46:17.206308Z","shell.execute_reply":"2024-09-03T13:46:17.210349Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"inception_model = InceptionV3Classifier(y_train=y_train)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:09.302765Z","iopub.execute_input":"2024-09-03T15:03:09.303162Z","iopub.status.idle":"2024-09-03T15:03:10.043306Z","shell.execute_reply.started":"2024-09-03T15:03:09.303131Z","shell.execute_reply":"2024-09-03T15:03:10.042489Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"inception_V3_model = ImageClassifier(inception_model, train_loader_InceptionV3, test_loader_InceptionV3)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:41:47.970029Z","iopub.execute_input":"2024-06-25T12:41:47.970442Z","iopub.status.idle":"2024-06-25T12:41:48.025147Z","shell.execute_reply.started":"2024-06-25T12:41:47.970412Z","shell.execute_reply":"2024-06-25T12:41:48.02444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_V3_model.fitt(epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:46:56.617842Z","iopub.execute_input":"2024-06-25T12:46:56.618335Z","iopub.status.idle":"2024-06-25T13:35:38.776476Z","shell.execute_reply.started":"2024-06-25T12:46:56.618286Z","shell.execute_reply":"2024-06-25T13:35:38.775689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_V3_model.Confussion_matrix()","metadata":{"execution":{"iopub.status.busy":"2024-06-25T13:35:38.777946Z","iopub.execute_input":"2024-06-25T13:35:38.778233Z","iopub.status.idle":"2024-06-25T13:37:51.178713Z","shell.execute_reply.started":"2024-06-25T13:35:38.778209Z","shell.execute_reply":"2024-06-25T13:37:51.177733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = '/kaggle/working/my_model_inception_v3.pth'\ninception_V3_model.save_model(save_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T13:38:04.764567Z","iopub.execute_input":"2024-06-25T13:38:04.764934Z","iopub.status.idle":"2024-06-25T13:38:04.949726Z","shell.execute_reply.started":"2024-06-25T13:38:04.764906Z","shell.execute_reply":"2024-06-25T13:38:04.948725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AlexNet(pl.LightningModule):\n    def __init__(self, num_classes=9, y_train=y_train):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n        \n        if y_train is not None:\n            y_train = torch.tensor(y_train)\n            class_sample_count = torch.tensor([(y_train == t).sum() for t in torch.unique(y_train)])\n            weight = 1. / class_sample_count.float()\n            self.class_weights = torch.FloatTensor(weight).to('cuda')\n        else:\n            self.class_weights = None\n        \n        self.criterion = nn.CrossEntropyLoss(weight=self.class_weights)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.criterion(logits, y)\n        self.log('train_loss', loss)\n        return loss\n\n    def configure_optimizers(self):\n        return optim.SGD(self.parameters(), lr=0.001)\n    \n    def on_train_epoch_end(self):\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:15.048645Z","iopub.execute_input":"2024-09-03T15:03:15.049634Z","iopub.status.idle":"2024-09-03T15:03:15.065493Z","shell.execute_reply.started":"2024-09-03T15:03:15.049596Z","shell.execute_reply":"2024-09-03T15:03:15.064529Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def image_transform2(image):\n    transform = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    return transform(image)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:17.407830Z","iopub.execute_input":"2024-09-03T15:03:17.408265Z","iopub.status.idle":"2024-09-03T15:03:17.414593Z","shell.execute_reply.started":"2024-09-03T15:03:17.408233Z","shell.execute_reply":"2024-09-03T15:03:17.413427Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_dataset_AlexNet = CustomImageDataset(x_train, y_train, transform=image_transform2)\ntest_dataset_AlexNet = CustomImageDataset(x_test, y_test, transform=image_transform2)\n\ntrain_loader_AlexNet = DataLoader(train_dataset_AlexNet, batch_size=16, shuffle=True)\ntest_loader_AlexNet = DataLoader(test_dataset_AlexNet, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:19.681555Z","iopub.execute_input":"2024-09-03T15:03:19.682414Z","iopub.status.idle":"2024-09-03T15:03:19.687713Z","shell.execute_reply.started":"2024-09-03T15:03:19.682380Z","shell.execute_reply":"2024-09-03T15:03:19.686750Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"Alexnet_model = AlexNet()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:03:22.255863Z","iopub.execute_input":"2024-09-03T15:03:22.256271Z","iopub.status.idle":"2024-09-03T15:03:22.871750Z","shell.execute_reply.started":"2024-09-03T15:03:22.256239Z","shell.execute_reply":"2024-09-03T15:03:22.870857Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"AlexNet_model = ImageClassifier(Alexnet_model, train_loader_AlexNet, test_loader_AlexNet)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:40:28.826236Z","iopub.execute_input":"2024-06-26T11:40:28.826541Z","iopub.status.idle":"2024-06-26T11:40:29.492711Z","shell.execute_reply.started":"2024-06-26T11:40:28.826514Z","shell.execute_reply":"2024-06-26T11:40:29.49185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fitt(epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T11:40:29.493802Z","iopub.execute_input":"2024-06-26T11:40:29.494082Z","iopub.status.idle":"2024-06-26T12:17:40.197027Z","shell.execute_reply.started":"2024-06-26T11:40:29.494057Z","shell.execute_reply":"2024-06-26T12:17:40.196038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AlexNet_model.Confussion_matrix()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T12:17:40.19997Z","iopub.execute_input":"2024-06-26T12:17:40.200703Z","iopub.status.idle":"2024-06-26T12:18:53.651543Z","shell.execute_reply.started":"2024-06-26T12:17:40.200669Z","shell.execute_reply":"2024-06-26T12:18:53.650563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = '/kaggle/working/my_model_AlexNet_model.pth'\nAlexNet_model.save_model(save_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T12:19:03.263022Z","iopub.execute_input":"2024-06-26T12:19:03.263872Z","iopub.status.idle":"2024-06-26T12:19:03.71308Z","shell.execute_reply.started":"2024-06-26T12:19:03.263837Z","shell.execute_reply":"2024-06-26T12:19:03.712288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saved_model_path_resnet = '/kaggle/input/restnet50model/pytorch/resnet/1/Restnet_50.pth'\nsaved_model_path_inception = '/kaggle/input/inceptionv3/pytorch/model_1/1/my_model_inception_v3.pth'\nsaved_model_path_alexnet = '/kaggle/input/alexnetwork/pytorch/model/1/AlexNet_model.pth'\n\nResNet_50_model_saved = ResNetClassifier(y_train=y_train)\nResNet_50_model_saved.load_state_dict(torch.load(saved_model_path_resnet))\n\nmodel_inception_v3_saved = InceptionV3Classifier(y_train=y_train)\nmodel_inception_v3_saved.load_state_dict(torch.load(saved_model_path_inception))\n\nmodel_alexnet_saved = AlexNet(y_train=y_train)\nmodel_alexnet_saved.load_state_dict(torch.load(saved_model_path_alexnet))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T15:30:38.429597Z","iopub.execute_input":"2024-09-03T15:30:38.430633Z","iopub.status.idle":"2024-09-03T15:30:40.964359Z","shell.execute_reply.started":"2024-09-03T15:30:38.430594Z","shell.execute_reply":"2024-09-03T15:30:40.963440Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def image_transform3(image):\n    transform = transforms.Compose([\n        transforms.Resize((299, 299)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    return transform(image)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:01:28.547215Z","iopub.execute_input":"2024-06-29T16:01:28.54755Z","iopub.status.idle":"2024-06-29T16:01:28.55309Z","shell.execute_reply.started":"2024-06-29T16:01:28.547522Z","shell.execute_reply":"2024-06-29T16:01:28.551999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_stacking = CustomImageDataset(x_train, y_train, transform=image_transform3)\ntest_dataset_stacking = CustomImageDataset(x_test, y_test, transform=image_transform3)\nval_dataset_stacking = CustomImageDataset(x_val, y_val, transform=image_transform3)\n\ntrain_loader_stacking = DataLoader(train_dataset_stacking, batch_size=16, shuffle=True)\ntest_loader_stacking = DataLoader(test_dataset_stacking, batch_size=16, shuffle=False)\nval_loader_stacking = DataLoader(val_dataset_stacking, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:34:00.029966Z","iopub.execute_input":"2024-06-27T15:34:00.030622Z","iopub.status.idle":"2024-06-27T15:34:00.037389Z","shell.execute_reply.started":"2024-06-27T15:34:00.030585Z","shell.execute_reply":"2024-06-27T15:34:00.036251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StackingMetaModel(pl.LightningModule):\n    def __init__(self, resnet_model = ResNet_50_model_saved, inception_model = model_inception_v3_saved, alexnet_model = model_alexnet_saved, num_classes=9, y_train=y_train):\n        super(StackingMetaModel, self).__init__()\n        self.resnet_model = resnet_model\n        self.inception_model = inception_model\n        self.alexnet_model = alexnet_model\n\n        self.meta_classifier = nn.Linear(3 * num_classes, num_classes)\n\n        self.val_losses = []\n        self.validation_step_outputs = []\n        self.training_step_outputs = []\n        \n        if y_train is not None:\n            y_train = torch.tensor(y_train)\n            class_sample_count = torch.tensor([(y_train == t).sum() for t in torch.unique(y_train)])\n            weight = 1. / class_sample_count.float()\n            self.class_weights = torch.FloatTensor(weight).to('cuda')\n        else:\n            self.class_weights = None\n        \n        self.criterion = nn.CrossEntropyLoss(weight=self.class_weights)\n\n        self.early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n\n    def forward(self, x):\n        resnet_output = self.resnet_model(x)\n        inception_output = self.inception_model(x)\n        alexnet_output = self.alexnet_model(x)\n\n        if hasattr(inception_output, 'logits'):\n            inception_output = inception_output.logits\n\n        stacked_output = torch.cat((resnet_output, inception_output, alexnet_output), dim=1)\n        return self.meta_classifier(stacked_output)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        loss = self.criterion(outputs, y)\n        self.log('train_loss', loss)\n        self.training_step_outputs.append(loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n        return optimizer\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        loss = self.criterion(outputs, y)\n        self.log('val_loss', loss)\n        self.validation_step_outputs.append(loss)\n\n    def on_validation_epoch_end(self):\n        avg_loss = torch.stack(self.validation_step_outputs).mean()\n        self.log('avg_val_loss', avg_loss)\n        self.validation_step_outputs.clear()\n\n    def on_train_epoch_end(self):\n        avg_loss = torch.stack(self.training_step_outputs).mean()\n        self.log('avg_train_loss', avg_loss)\n        self.training_step_outputs.clear()\n\n    def configure_callbacks(self):\n        return [self.early_stopping]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:34:07.384975Z","iopub.execute_input":"2024-06-27T15:34:07.385746Z","iopub.status.idle":"2024-06-27T15:34:07.403443Z","shell.execute_reply.started":"2024-06-27T15:34:07.385708Z","shell.execute_reply":"2024-06-27T15:34:07.402267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_meta_model = StackingMetaModel()\nStacking_Meta_Model = ImageClassifier(stacking_meta_model, train_loader_stacking, test_loader_stacking, val_loader_stacking)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:34:15.679702Z","iopub.execute_input":"2024-06-27T15:34:15.680408Z","iopub.status.idle":"2024-06-27T15:34:16.448061Z","shell.execute_reply.started":"2024-06-27T15:34:15.680373Z","shell.execute_reply":"2024-06-27T15:34:16.446986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Stacking_Meta_Model.fitt(epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T15:34:19.799858Z","iopub.execute_input":"2024-06-27T15:34:19.800243Z","iopub.status.idle":"2024-06-27T16:39:32.067038Z","shell.execute_reply.started":"2024-06-27T15:34:19.800212Z","shell.execute_reply":"2024-06-27T16:39:32.066146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Stacking_Meta_Model.Confussion_matrix()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:39:32.069011Z","iopub.execute_input":"2024-06-27T16:39:32.069305Z","iopub.status.idle":"2024-06-27T16:42:32.247842Z","shell.execute_reply.started":"2024-06-27T16:39:32.069278Z","shell.execute_reply":"2024-06-27T16:42:32.246671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = '/kaggle/working/my_model_Stacking.pth'\nStacking_Meta_Model.save_model(save_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:42:38.788884Z","iopub.execute_input":"2024-06-27T16:42:38.789543Z","iopub.status.idle":"2024-06-27T16:42:39.60963Z","shell.execute_reply.started":"2024-06-27T16:42:38.789505Z","shell.execute_reply":"2024-06-27T16:42:39.608536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_voting = CustomImageDataset(x_train, y_train, transform=image_transform3)\ntest_dataset_voting = CustomImageDataset(x_test, y_test, transform=image_transform3)\nval_dataset_voting = CustomImageDataset(x_val, y_val, transform=image_transform3)\n\ntrain_loader_voting = DataLoader(train_dataset_voting, batch_size=32, shuffle=True)\ntest_loader_voting = DataLoader(test_dataset_voting, batch_size=32, shuffle=False)\nval_loader_voting = DataLoader(val_dataset_voting, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:01:28.554284Z","iopub.execute_input":"2024-06-29T16:01:28.554652Z","iopub.status.idle":"2024-06-29T16:01:28.56862Z","shell.execute_reply.started":"2024-06-29T16:01:28.554627Z","shell.execute_reply":"2024-06-29T16:01:28.567799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VotingMetaModel(pl.LightningModule):\n    def __init__(self, resnet_model=ResNet_50_model_saved, inception_model=model_inception_v3_saved, alexnet_model=model_alexnet_saved, num_classes=9):\n        super(VotingMetaModel, self).__init__()\n        self.resnet_model = resnet_model\n        self.inception_model = inception_model\n        self.alexnet_model = alexnet_model\n\n        self.val_losses = []\n        self.validation_step_outputs = []\n        self.training_step_outputs = []\n\n        self.early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n\n    def forward(self, x):\n        resnet_output = self.resnet_model(x)\n        inception_output = self.inception_model(x)\n        alexnet_output = self.alexnet_model(x)\n\n        if hasattr(inception_output, 'logits'):\n            inception_output = inception_output.logits\n\n        outputs = [resnet_output, inception_output, alexnet_output]\n\n        avg_output = torch.mean(torch.stack(outputs), dim=0)\n        return avg_output\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        loss = nn.functional.cross_entropy(outputs, y)\n        self.log('train_loss', loss)\n        self.training_step_outputs.append(loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n        return optimizer\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        outputs = self(x)\n        loss = nn.functional.cross_entropy(outputs, y)\n        self.log('val_loss', loss)\n        self.validation_step_outputs.append(loss)\n\n    def on_validation_epoch_end(self):\n        avg_loss = torch.stack(self.validation_step_outputs).mean()\n        self.log('avg_val_loss', avg_loss)\n        self.validation_step_outputs.clear()\n\n    def on_train_epoch_end(self):\n        avg_loss = torch.stack(self.training_step_outputs).mean()\n        self.log('avg_train_loss', avg_loss)\n        self.training_step_outputs.clear()\n\n    def configure_callbacks(self):\n        return [self.early_stopping]","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:06:25.471119Z","iopub.execute_input":"2024-06-29T16:06:25.471702Z","iopub.status.idle":"2024-06-29T16:06:25.493491Z","shell.execute_reply.started":"2024-06-29T16:06:25.471662Z","shell.execute_reply":"2024-06-29T16:06:25.492282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voting_meta_model_soft = VotingMetaModel()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T15:56:31.2075Z","iopub.execute_input":"2024-06-29T15:56:31.208417Z","iopub.status.idle":"2024-06-29T15:56:31.212898Z","shell.execute_reply.started":"2024-06-29T15:56:31.208383Z","shell.execute_reply":"2024-06-29T15:56:31.211947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Voting_Meta_Model = ImageClassifier(voing_meta_model_soft, train_loader_voting, test_loader_voting, val_loader_voting)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:06:20.230626Z","iopub.execute_input":"2024-06-29T16:06:20.231361Z","iopub.status.idle":"2024-06-29T16:06:20.277014Z","shell.execute_reply.started":"2024-06-29T16:06:20.231329Z","shell.execute_reply":"2024-06-29T16:06:20.27572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Voting_Meta_Model.fitt(epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:06:14.747243Z","iopub.execute_input":"2024-06-29T16:06:14.747875Z","iopub.status.idle":"2024-06-29T16:06:14.792911Z","shell.execute_reply.started":"2024-06-29T16:06:14.747842Z","shell.execute_reply":"2024-06-29T16:06:14.7917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Voting_Meta_Model.Confussion_matrix()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T14:54:49.461456Z","iopub.execute_input":"2024-06-29T14:54:49.462262Z","iopub.status.idle":"2024-06-29T14:59:10.367567Z","shell.execute_reply.started":"2024-06-29T14:54:49.462227Z","shell.execute_reply":"2024-06-29T14:59:10.366589Z"},"trusted":true},"execution_count":null,"outputs":[]}]}